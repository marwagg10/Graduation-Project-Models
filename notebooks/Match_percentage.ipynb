{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMwffP_PVk8J",
        "outputId": "a4e5d5cd-07ee-43ac-c99f-471f512aa1b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xXh2VxuVoZo",
        "outputId": "5ccd6cf6-c3de-48b4-9d56-dc2da7518f3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UprXmg4dJadV",
        "outputId": "78d1935f-ea52-4153-850d-3630cbaabb4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzh9zS9_g9Op",
        "outputId": "6ea34c52-5f15-4477-8f07-bf8449ffcb64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: altair in /usr/local/lib/python3.12/dist-packages (5.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair) (2.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from altair) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from altair) (4.15.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair) (0.27.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install altair"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from joblib import load\n",
        "import altair as alt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Download NLTK resources\n",
        "@st.cache_resource\n",
        "def download_nltk_resources():\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('wordnet')\n",
        "    nltk.download(\"punkt_tab\")\n",
        "\n",
        "download_nltk_resources()\n",
        "\n",
        "# Load dataset\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    return pd.read_csv('/content/Data_project (1).csv')\n",
        "\n",
        "df = load_data()\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = load('/content/best_rf_model (1).pkl')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Preprocessing functions\n",
        "def preprocess(text):\n",
        "    text = BeautifulSoup(str(text), \"html.parser\").get_text()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t.lower() for t in tokens if t.isalpha() and t.lower() not in stop_words]\n",
        "    return ' '.join([lemmatizer.lemmatize(t) for t in tokens])\n",
        "\n",
        "# Handling job requirements\n",
        "df[\"Processed_Requirments\"] = df[\"Requirments\"].fillna(\"\").apply(preprocess)\n",
        "\n",
        "# Converting texts to a vector using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "job_tfidf = vectorizer.fit_transform(df[\"Processed_Requirments\"])\n",
        "\n",
        "# Initialize LabelEncoders\n",
        "le_job_title = LabelEncoder()\n",
        "le_company = LabelEncoder()\n",
        "le_location = LabelEncoder()\n",
        "le_country = LabelEncoder()\n",
        "le_employment = LabelEncoder()\n",
        "le_experience = LabelEncoder()\n",
        "\n",
        "# Fit encoders on the data (assuming column names match; adjust if needed)\n",
        "df['Job Title Encoded'] = le_job_title.fit_transform(df['Job Title'].fillna('Unknown'))\n",
        "df['Company Name Encoded'] = le_company.fit_transform(df['Company Name: '].fillna('Unknown'))  # Adjusted column name without colon/space\n",
        "df['Location Encoded'] = le_location.fit_transform(df['Location'].fillna('Unknown'))\n",
        "df['Country Encoded'] = le_country.fit_transform(df['Country'].fillna('Unknown'))\n",
        "df['Employment Type Encoded'] = le_employment.fit_transform(df['Employment Type'].fillna('Unknown'))\n",
        "df['Experience Needed Encoded'] = le_experience.fit_transform(df['Experience Needed'].fillna('Unknown'))\n",
        "\n",
        "# App Title\n",
        "st.title(\"🔍 Job Matching Using ML & Similarity\")\n",
        "st.markdown(\"Enter your skills and discover matching jobs using AI.\")\n",
        "\n",
        "# User input\n",
        "raw_skills = st.text_area(\"Enter your skills (free text):\", height=150)\n",
        "\n",
        "if st.button(\"Check Matching Jobs\"):\n",
        "    if raw_skills.strip() == \"\":\n",
        "        st.warning(\"Please enter your skills first.\")\n",
        "    else:\n",
        "        user_input_processed = preprocess(raw_skills)\n",
        "        user_tfidf = vectorizer.transform([user_input_processed])\n",
        "\n",
        "        # Cosine similarity\n",
        "        cosine_scores = cosine_similarity(user_tfidf, job_tfidf)[0]\n",
        "        df[\"Cosine_Similarity\"] = cosine_scores\n",
        "        df[\"Match_Percentage\"] = (cosine_scores * 100).round(2)\n",
        "\n",
        "        # Creating features for the model (using encoded categorical features + Cosine_Similarity)\n",
        "        features = pd.DataFrame({\n",
        "            \"Job Title Encoded\": df['Job Title Encoded'],\n",
        "            \"Company Name Encoded\": df['Company Name Encoded'],\n",
        "            \"Location Encoded\": df['Location Encoded'],\n",
        "            \"Country Encoded\": df['Country Encoded'],\n",
        "            \"Employment Type Encoded\": df['Employment Type Encoded'],\n",
        "            \"Experience Needed Encoded\": df['Experience Needed Encoded'],\n",
        "            \"Cosine_Similarity\": cosine_scores\n",
        "        })\n",
        "\n",
        "        # Verify the number of features\n",
        "        if model.n_features_in_ != features.shape[1]:\n",
        "            st.error(f\"Model expects {model.n_features_in_} features, but provided {features.shape[1]} features.\")\n",
        "        else:\n",
        "            # Predict the matching percentage through the model\n",
        "            df[\"Predicted_Match\"] = model.predict(features).round(2)\n",
        "\n",
        "            # Get top 5 matches\n",
        "            top_matches = df.sort_values(by=\"Predicted_Match\", ascending=False).head(5)\n",
        "\n",
        "            if top_matches[\"Predicted_Match\"].max() == 0:\n",
        "                st.warning(\"No jobs matched your input skills.\")\n",
        "            else:\n",
        "                st.success(\"Top 5 matching jobs predicted!\")\n",
        "\n",
        "                st.subheader(\"Matching Results (JSON Format):\")\n",
        "                st.json(top_matches[[\"Job Title\", \"Predicted_Match\"]].rename(columns={\"Predicted_Match\": \"Match Percentage\"}).to_dict(orient='records'))\n",
        "\n",
        "                # Chart\n",
        "                chart = alt.Chart(top_matches).mark_bar().encode(\n",
        "                    x=alt.X('Predicted_Match:Q', title=\"Predicted Match %\"),\n",
        "                    y=alt.Y('Job Title:N', sort='-x'),\n",
        "                    color=alt.Color('Predicted_Match:Q', scale=alt.Scale(scheme='greens'))\n",
        "                ).properties(height=400)\n",
        "                st.altair_chart(chart, use_container_width=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH5y_06v7APA",
        "outputId": "808e6484-a3bb-46be-dac1-731983e575f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0SLp7LXbf3r",
        "outputId": "faccc233-c9e0-40a0-ced4-5435945bde81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# set up ngrok key with your token\n",
        "!ngrok authtoken 2pX4hfQcyBJZD9vQgF7AtMBRdbO_89seFXrKL2n7x68afsvBM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GKq3oYYnbgpd"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "# create page as html file\n",
        "!streamlit run app.py &>/dev/null&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JncbyKexbnkV",
        "outputId": "ab812ae8-472a-48b8-b5c1-98a8d075ed45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "893\n"
          ]
        }
      ],
      "source": [
        "!pgrep -f streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICIeiZkQbsAm",
        "outputId": "9d77a364-16be-441a-c7af-dd1d96b3b0f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://91b3fe19f6c4.ngrok-free.app\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "public_url = ngrok.connect(8501)\n",
        "public_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovoDf4MFbvLv"
      },
      "outputs": [],
      "source": [
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}